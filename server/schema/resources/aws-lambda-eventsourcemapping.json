{
  "tagging": {
    "taggable": false,
    "tagOnCreate": false,
    "tagUpdatable": false,
    "cloudFormationSystemTags": false
  },
  "propertyTransform": {
    "/properties/StartingPositionTimestamp": "StartingPositionTimestamp * 1000"
  },
  "handlers": {
    "read": {
      "permissions": [
        "lambda:GetEventSourceMapping"
      ]
    },
    "create": {
      "permissions": [
        "lambda:CreateEventSourceMapping",
        "lambda:GetEventSourceMapping"
      ]
    },
    "update": {
      "permissions": [
        "lambda:UpdateEventSourceMapping",
        "lambda:GetEventSourceMapping"
      ]
    },
    "list": {
      "permissions": [
        "lambda:ListEventSourceMappings"
      ]
    },
    "delete": {
      "permissions": [
        "lambda:DeleteEventSourceMapping",
        "lambda:GetEventSourceMapping"
      ]
    }
  },
  "typeName": "AWS::Lambda::EventSourceMapping",
  "readOnlyProperties": [
    "/properties/Id"
  ],
  "description": "The ``AWS::Lambda::EventSourceMapping`` resource creates a mapping between an event source and an LAMlong function. LAM reads items from the event source and triggers the function.\n For details about each event source type, see the following topics. In particular, each of the topics describes the required and optional parameters for the specific event source. \n  +   [Configuring a Dynamo DB stream as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-ddb.html#services-dynamodb-eventsourcemapping) \n  +   [Configuring a Kinesis stream as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-kinesis.html#services-kinesis-eventsourcemapping) \n  +   [Configuring an SQS queue as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-eventsource) \n  +   [Configuring an MQ broker as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-mq.html#services-mq-eventsourcemapping) \n  +   [Configuring MSK as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html) \n  +   [Configuring Self-Managed Apache Kafka as an event source](https://docs.aws.amazon.com/lambda/latest/dg/kafka-smaa.html) \n  +   [Configuring Amazon DocumentDB as an event source](https://docs.aws.amazon.com/lambda/latest/dg/with-documentdb.html)",
  "createOnlyProperties": [
    "/properties/EventSourceArn",
    "/properties/StartingPosition",
    "/properties/StartingPositionTimestamp",
    "/properties/SelfManagedEventSource",
    "/properties/AmazonManagedKafkaEventSourceConfig",
    "/properties/SelfManagedKafkaEventSourceConfig"
  ],
  "additionalProperties": false,
  "primaryIdentifier": [
    "/properties/Id"
  ],
  "definitions": {
    "ScalingConfig": {
      "description": "(Amazon SQS only) The scaling configuration for the event source. To remove the configuration, pass an empty value.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "MaximumConcurrency": {
          "description": "Limits the number of concurrent instances that the SQS event source can invoke.",
          "$ref": "#/definitions/MaximumConcurrency",
          "markdownDescription": "Limits the number of concurrent instances that the SQS event source can invoke.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "(Amazon SQS only) The scaling configuration for the event source. To remove the configuration, pass an empty value.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "SelfManagedEventSource": {
      "description": "The self-managed Apache Kafka cluster for your event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "Endpoints": {
          "description": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.",
          "$ref": "#/definitions/Endpoints",
          "markdownDescription": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "The self-managed Apache Kafka cluster for your event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "MaximumConcurrency": {
      "description": "The maximum number of concurrent functions that an event source can invoke.",
      "maximum": 1000,
      "type": "integer",
      "minimum": 2,
      "markdownDescription": "The maximum number of concurrent functions that an event source can invoke.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "SourceAccessConfiguration": {
      "description": "An array of the authentication protocol, VPC components, or virtual host to secure and define your event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "Type": {
          "description": "The type of authentication protocol, VPC components, or virtual host for your event source. For example: ``\"Type\":\"SASL_SCRAM_512_AUTH\"``.\n  +   ``BASIC_AUTH`` \u2013 (Amazon MQ) The ASMlong secret that stores your broker credentials.\n  +   ``BASIC_AUTH`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL/PLAIN authentication of your Apache Kafka brokers.\n  +   ``VPC_SUBNET`` \u2013 (Self-managed Apache Kafka) The subnets associated with your VPC. Lambda connects to these subnets to fetch data from your self-managed Apache Kafka cluster.\n  +   ``VPC_SECURITY_GROUP`` \u2013 (Self-managed Apache Kafka) The VPC security group used to manage access to your self-managed Apache Kafka brokers.\n  +   ``SASL_SCRAM_256_AUTH`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL SCRAM-256 authentication of your self-managed Apache Kafka brokers.\n  +   ``SASL_SCRAM_512_AUTH`` \u2013 (Amazon MSK, Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL SCRAM-512 authentication of your self-managed Apache Kafka brokers.\n  +   ``VIRTUAL_HOST`` \u2013- (RabbitMQ) The name of the virtual host in your RabbitMQ broker. Lambda uses this RabbitMQ host as the event source. This property cannot be specified in an UpdateEventSourceMapping API call.\n  +   ``CLIENT_CERTIFICATE_TLS_AUTH`` \u2013 (Amazon MSK, self-managed Apache Kafka) The Secrets Manager ARN of your secret key containing the certificate chain (X.509 PEM), private key (PKCS#8 PEM), and private key password (optional) used for mutual TLS authentication of your MSK/Apache Kafka brokers.\n  +   ``SERVER_ROOT_CA_CERTIFICATE`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key containing the root CA certificate (X.509 PEM) used for TLS encryption of your Apache Kafka brokers.",
          "type": "string",
          "enum": [
            "BASIC_AUTH",
            "VPC_SUBNET",
            "VPC_SECURITY_GROUP",
            "SASL_SCRAM_512_AUTH",
            "SASL_SCRAM_256_AUTH",
            "VIRTUAL_HOST",
            "CLIENT_CERTIFICATE_TLS_AUTH",
            "SERVER_ROOT_CA_CERTIFICATE"
          ],
          "markdownDescription": "The type of authentication protocol, VPC components, or virtual host for your event source. For example: ``\"Type\":\"SASL_SCRAM_512_AUTH\"``.\n  +   ``BASIC_AUTH`` \u2013 (Amazon MQ) The ASMlong secret that stores your broker credentials.\n  +   ``BASIC_AUTH`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL/PLAIN authentication of your Apache Kafka brokers.\n  +   ``VPC_SUBNET`` \u2013 (Self-managed Apache Kafka) The subnets associated with your VPC. Lambda connects to these subnets to fetch data from your self-managed Apache Kafka cluster.\n  +   ``VPC_SECURITY_GROUP`` \u2013 (Self-managed Apache Kafka) The VPC security group used to manage access to your self-managed Apache Kafka brokers.\n  +   ``SASL_SCRAM_256_AUTH`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL SCRAM-256 authentication of your self-managed Apache Kafka brokers.\n  +   ``SASL_SCRAM_512_AUTH`` \u2013 (Amazon MSK, Self-managed Apache Kafka) The Secrets Manager ARN of your secret key used for SASL SCRAM-512 authentication of your self-managed Apache Kafka brokers.\n  +   ``VIRTUAL_HOST`` \u2013- (RabbitMQ) The name of the virtual host in your RabbitMQ broker. Lambda uses this RabbitMQ host as the event source. This property cannot be specified in an UpdateEventSourceMapping API call.\n  +   ``CLIENT_CERTIFICATE_TLS_AUTH`` \u2013 (Amazon MSK, self-managed Apache Kafka) The Secrets Manager ARN of your secret key containing the certificate chain (X.509 PEM), private key (PKCS#8 PEM), and private key password (optional) used for mutual TLS authentication of your MSK/Apache Kafka brokers.\n  +   ``SERVER_ROOT_CA_CERTIFICATE`` \u2013 (Self-managed Apache Kafka) The Secrets Manager ARN of your secret key containing the root CA certificate (X.509 PEM) used for TLS encryption of your Apache Kafka brokers.\n\n---\n\nRequired: No  \nType: String  \nAllowed Values: BASIC_AUTH | VPC_SUBNET | VPC_SECURITY_GROUP | SASL_SCRAM_512_AUTH | SASL_SCRAM_256_AUTH | VIRTUAL_HOST | CLIENT_CERTIFICATE_TLS_AUTH | SERVER_ROOT_CA_CERTIFICATE  \nUpdate requires: No interruption"
        },
        "URI": {
          "minLength": 1,
          "description": "The value for your chosen configuration in ``Type``. For example: ``\"URI\": \"arn:aws:secretsmanager:us-east-1:01234567890:secret:MyBrokerSecretName\"``.",
          "type": "string",
          "maxLength": 200,
          "markdownDescription": "The value for your chosen configuration in ``Type``. For example: ``\"URI\": \"arn:aws:secretsmanager:us-east-1:01234567890:secret:MyBrokerSecretName\"``.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 200  \nPattern: [a-zA-Z0-9-\\/*:_+=.@-]*  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "An array of the authentication protocol, VPC components, or virtual host to secure and define your event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "FilterCriteria": {
      "description": "An object that contains the filters for an event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "Filters": {
          "minItems": 1,
          "maxItems": 20,
          "uniqueItems": true,
          "description": "A list of filters.",
          "type": "array",
          "items": {
            "$ref": "#/definitions/Filter"
          },
          "markdownDescription": "A list of filters.\n\n---\n\nRequired: No  \nType: Array  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "An object that contains the filters for an event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "SelfManagedKafkaEventSourceConfig": {
      "description": "Specific configuration settings for a self-managed Apache Kafka event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "ConsumerGroupId": {
          "description": "The identifier for the Kafka consumer group to join. The consumer group ID must be unique among all your Kafka event sources. After creating a Kafka event source mapping with the consumer group ID specified, you cannot update this value. For more information, see [Customizable consumer group ID](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-consumer-group-id).",
          "$ref": "#/definitions/ConsumerGroupId",
          "markdownDescription": "The identifier for the Kafka consumer group to join. The consumer group ID must be unique among all your Kafka event sources. After creating a Kafka event source mapping with the consumer group ID specified, you cannot update this value. For more information, see [Customizable consumer group ID](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-consumer-group-id).\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "Specific configuration settings for a self-managed Apache Kafka event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "DocumentDBEventSourceConfig": {
      "description": "Specific configuration settings for a DocumentDB event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "FullDocument": {
          "description": "Determines what DocumentDB sends to your event stream during document update operations. If set to UpdateLookup, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes.",
          "type": "string",
          "enum": [
            "UpdateLookup",
            "Default"
          ],
          "markdownDescription": "Determines what DocumentDB sends to your event stream during document update operations. If set to UpdateLookup, DocumentDB sends a delta describing the changes, along with a copy of the entire document. Otherwise, DocumentDB sends only a partial document that contains the changes.\n\n---\n\nRequired: No  \nType: String  \nAllowed Values: UpdateLookup | Default  \nUpdate requires: No interruption"
        },
        "CollectionName": {
          "minLength": 1,
          "description": "The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.",
          "type": "string",
          "maxLength": 57,
          "markdownDescription": "The name of the collection to consume within the database. If you do not specify a collection, Lambda consumes all collections.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 57  \nUpdate requires: No interruption"
        },
        "DatabaseName": {
          "minLength": 1,
          "description": "The name of the database to consume within the DocumentDB cluster.",
          "type": "string",
          "maxLength": 63,
          "markdownDescription": "The name of the database to consume within the DocumentDB cluster.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 63  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "Specific configuration settings for a DocumentDB event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "Endpoints": {
      "description": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "KafkaBootstrapServers": {
          "minItems": 1,
          "maxItems": 10,
          "uniqueItems": true,
          "description": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.",
          "type": "array",
          "items": {
            "minLength": 1,
            "description": "The URL of a Kafka server.",
            "type": "string",
            "maxLength": 300,
            "markdownDescription": "The URL of a Kafka server.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 300  \nPattern: ^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\\-]*[a-zA-Z0-9])\\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\\-]*[A-Za-z0-9]):[0-9]{1,5}  \nUpdate requires: No interruption"
          },
          "markdownDescription": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.\n\n---\n\nRequired: No  \nType: Array  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "The list of bootstrap servers for your Kafka brokers in the following format: ``\"KafkaBootstrapServers\": [\"abc.xyz.com:xxxx\",\"abc2.xyz.com:xxxx\"]``.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "DestinationConfig": {
      "description": "A configuration object that specifies the destination of an event after Lambda processes it.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "OnFailure": {
          "description": "The destination configuration for failed invocations.",
          "$ref": "#/definitions/OnFailure",
          "markdownDescription": "The destination configuration for failed invocations.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "A configuration object that specifies the destination of an event after Lambda processes it.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "ConsumerGroupId": {
      "minLength": 1,
      "description": "The identifier for the Kafka Consumer Group to join.",
      "type": "string",
      "maxLength": 200,
      "markdownDescription": "The identifier for the Kafka Consumer Group to join.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 200  \nPattern: [a-zA-Z0-9-\\/*:_+=.@-]*  \nUpdate requires: No interruption"
    },
    "Filter": {
      "description": "A structure within a ``FilterCriteria`` object that defines an event filtering pattern.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "Pattern": {
          "minLength": 0,
          "description": "A filter pattern. For more information on the syntax of a filter pattern, see [Filter rule syntax](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-syntax).",
          "type": "string",
          "maxLength": 4096,
          "markdownDescription": "A filter pattern. For more information on the syntax of a filter pattern, see [Filter rule syntax](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html#filtering-syntax).\n\n---\n\nRequired: No  \nType: String  \nMaximum Length: 4096  \nPattern: .*  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "A structure within a ``FilterCriteria`` object that defines an event filtering pattern.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "AmazonManagedKafkaEventSourceConfig": {
      "description": "Specific configuration settings for an Amazon Managed Streaming for Apache Kafka (Amazon MSK) event source.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "ConsumerGroupId": {
          "description": "The identifier for the Kafka consumer group to join. The consumer group ID must be unique among all your Kafka event sources. After creating a Kafka event source mapping with the consumer group ID specified, you cannot update this value. For more information, see [Customizable consumer group ID](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-consumer-group-id).",
          "$ref": "#/definitions/ConsumerGroupId",
          "markdownDescription": "The identifier for the Kafka consumer group to join. The consumer group ID must be unique among all your Kafka event sources. After creating a Kafka event source mapping with the consumer group ID specified, you cannot update this value. For more information, see [Customizable consumer group ID](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-consumer-group-id).\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "Specific configuration settings for an Amazon Managed Streaming for Apache Kafka (Amazon MSK) event source.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    },
    "OnFailure": {
      "description": "A destination for events that failed processing.",
      "additionalProperties": false,
      "type": "object",
      "properties": {
        "Destination": {
          "minLength": 12,
          "description": "The Amazon Resource Name (ARN) of the destination resource.\n To retain records of [asynchronous invocations](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations), you can configure an Amazon SNS topic, Amazon SQS queue, Lambda function, or Amazon EventBridge event bus as the destination.\n To retain records of failed invocations from [Kinesis and DynamoDB event sources](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html#event-source-mapping-destinations), you can configure an Amazon SNS topic or Amazon SQS queue as the destination.\n To retain records of failed invocations from [self-managed Kafka](https://docs.aws.amazon.com/lambda/latest/dg/with-kafka.html#services-smaa-onfailure-destination) or [Amazon MSK](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-onfailure-destination), you can configure an Amazon SNS topic, Amazon SQS queue, or Amazon S3 bucket as the destination.",
          "type": "string",
          "maxLength": 1024,
          "markdownDescription": "The Amazon Resource Name (ARN) of the destination resource.\n To retain records of [asynchronous invocations](https://docs.aws.amazon.com/lambda/latest/dg/invocation-async.html#invocation-async-destinations), you can configure an Amazon SNS topic, Amazon SQS queue, Lambda function, or Amazon EventBridge event bus as the destination.\n To retain records of failed invocations from [Kinesis and DynamoDB event sources](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventsourcemapping.html#event-source-mapping-destinations), you can configure an Amazon SNS topic or Amazon SQS queue as the destination.\n To retain records of failed invocations from [self-managed Kafka](https://docs.aws.amazon.com/lambda/latest/dg/with-kafka.html#services-smaa-onfailure-destination) or [Amazon MSK](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#services-msk-onfailure-destination), you can configure an Amazon SNS topic, Amazon SQS queue, or Amazon S3 bucket as the destination.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 12  \nMaximum Length: 1024  \nPattern: arn:(aws[a-zA-Z0-9-]*):([a-zA-Z0-9\\-])+:([a-z]{2}(-gov)?(-iso([a-z])?)?-[a-z]+-\\d{1})?:(\\d{12})?:(.*)  \nUpdate requires: No interruption"
        }
      },
      "markdownDescription": "A destination for events that failed processing.\n\n---\n\nRequired: No  \nUpdate requires: No interruption"
    }
  },
  "required": [
    "FunctionName"
  ],
  "properties": {
    "StartingPosition": {
      "minLength": 6,
      "description": "The position in a stream from which to start reading. Required for Amazon Kinesis and Amazon DynamoDB.\n  +   *LATEST* - Read only new records.\n  +   *TRIM_HORIZON* - Process all available records.\n  +   *AT_TIMESTAMP* - Specify a time from which to start reading records.",
      "type": "string",
      "maxLength": 12,
      "markdownDescription": "The position in a stream from which to start reading. Required for Amazon Kinesis and Amazon DynamoDB.\n  +   *LATEST* - Read only new records.\n  +   *TRIM_HORIZON* - Process all available records.\n  +   *AT_TIMESTAMP* - Specify a time from which to start reading records.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 6  \nMaximum Length: 12  \nPattern: (LATEST|TRIM_HORIZON|AT_TIMESTAMP)+  \nUpdate requires: Replacement"
    },
    "SelfManagedEventSource": {
      "description": "The self-managed Apache Kafka cluster for your event source.",
      "$ref": "#/definitions/SelfManagedEventSource",
      "markdownDescription": "The self-managed Apache Kafka cluster for your event source.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: Replacement"
    },
    "ParallelizationFactor": {
      "description": "(Kinesis and DynamoDB Streams only) The number of batches to process concurrently from each shard. The default value is 1.",
      "maximum": 10,
      "type": "integer",
      "minimum": 1,
      "markdownDescription": "(Kinesis and DynamoDB Streams only) The number of batches to process concurrently from each shard. The default value is 1.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "FilterCriteria": {
      "description": "An object that defines the filter criteria that determine whether Lambda should process an event. For more information, see [Lambda event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html).",
      "$ref": "#/definitions/FilterCriteria",
      "markdownDescription": "An object that defines the filter criteria that determine whether Lambda should process an event. For more information, see [Lambda event filtering](https://docs.aws.amazon.com/lambda/latest/dg/invocation-eventfiltering.html).\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
    },
    "FunctionName": {
      "minLength": 1,
      "description": "The name or ARN of the Lambda function.\n  **Name formats**\n +   *Function name* \u2013 ``MyFunction``.\n  +   *Function ARN* \u2013 ``arn:aws:lambda:us-west-2:123456789012:function:MyFunction``.\n  +   *Version or Alias ARN* \u2013 ``arn:aws:lambda:us-west-2:123456789012:function:MyFunction:PROD``.\n  +   *Partial ARN* \u2013 ``123456789012:function:MyFunction``.\n  \n The length constraint applies only to the full ARN. If you specify only the function name, it's limited to 64 characters in length.",
      "type": "string",
      "maxLength": 140,
      "markdownDescription": "The name or ARN of the Lambda function.\n  **Name formats**\n +   *Function name* \u2013 ``MyFunction``.\n  +   *Function ARN* \u2013 ``arn:aws:lambda:us-west-2:123456789012:function:MyFunction``.\n  +   *Version or Alias ARN* \u2013 ``arn:aws:lambda:us-west-2:123456789012:function:MyFunction:PROD``.\n  +   *Partial ARN* \u2013 ``123456789012:function:MyFunction``.\n  \n The length constraint applies only to the full ARN. If you specify only the function name, it's limited to 64 characters in length.\n\n---\n\nRequired: Yes  \nType: String  \nMinimum Length: 1  \nMaximum Length: 140  \nPattern: (arn:(aws[a-zA-Z-]*)?:lambda:)?([a-z]{2}(-gov)?(-iso([a-z])?)?-[a-z]+-\\d{1}:)?(\\d{12}:)?(function:)?([a-zA-Z0-9-_]+)(:(\\$LATEST|[a-zA-Z0-9-_]+))?  \nUpdate requires: No interruption"
    },
    "DestinationConfig": {
      "description": "(Kinesis, DynamoDB Streams, Amazon MSK, and self-managed Apache Kafka event sources only) A configuration object that specifies the destination of an event after Lambda processes it.",
      "$ref": "#/definitions/DestinationConfig",
      "markdownDescription": "(Kinesis, DynamoDB Streams, Amazon MSK, and self-managed Apache Kafka event sources only) A configuration object that specifies the destination of an event after Lambda processes it.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
    },
    "AmazonManagedKafkaEventSourceConfig": {
      "description": "Specific configuration settings for an Amazon Managed Streaming for Apache Kafka (Amazon MSK) event source.",
      "$ref": "#/definitions/AmazonManagedKafkaEventSourceConfig",
      "markdownDescription": "Specific configuration settings for an Amazon Managed Streaming for Apache Kafka (Amazon MSK) event source.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: Replacement"
    },
    "SourceAccessConfigurations": {
      "minItems": 1,
      "maxItems": 22,
      "uniqueItems": true,
      "description": "An array of the authentication protocol, VPC components, or virtual host to secure and define your event source.",
      "type": "array",
      "items": {
        "$ref": "#/definitions/SourceAccessConfiguration"
      },
      "markdownDescription": "An array of the authentication protocol, VPC components, or virtual host to secure and define your event source.\n\n---\n\nRequired: No  \nType: Array  \nUpdate requires: No interruption"
    },
    "MaximumBatchingWindowInSeconds": {
      "description": "The maximum amount of time, in seconds, that Lambda spends gathering records before invoking the function.\n  *Default (, , event sources)*: 0\n  *Default (, Kafka, , event sources)*: 500 ms\n  *Related setting:* For SQS event sources, when you set ``BatchSize`` to a value greater than 10, you must set ``MaximumBatchingWindowInSeconds`` to at least 1.",
      "maximum": 300,
      "type": "integer",
      "minimum": 0,
      "markdownDescription": "The maximum amount of time, in seconds, that Lambda spends gathering records before invoking the function.\n  *Default (, , event sources)*: 0\n  *Default (, Kafka, , event sources)*: 500 ms\n  *Related setting:* For SQS event sources, when you set ``BatchSize`` to a value greater than 10, you must set ``MaximumBatchingWindowInSeconds`` to at least 1.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "BatchSize": {
      "description": "The maximum number of records in each batch that Lambda pulls from your stream or queue and sends to your function. Lambda passes all of the records in the batch to the function in a single call, up to the payload limit for synchronous invocation (6 MB).\n  +   *Amazon Kinesis* \u2013 Default 100. Max 10,000.\n  +   *Amazon DynamoDB Streams* \u2013 Default 100. Max 10,000.\n  +   *Amazon Simple Queue Service* \u2013 Default 10. For standard queues the max is 10,000. For FIFO queues the max is 10.\n  +   *Amazon Managed Streaming for Apache Kafka* \u2013 Default 100. Max 10,000.\n  +   *Self-managed Apache Kafka* \u2013 Default 100. Max 10,000.\n  +   *Amazon MQ (ActiveMQ and RabbitMQ)* \u2013 Default 100. Max 10,000.\n  +   *DocumentDB* \u2013 Default 100. Max 10,000.",
      "maximum": 10000,
      "type": "integer",
      "minimum": 1,
      "markdownDescription": "The maximum number of records in each batch that Lambda pulls from your stream or queue and sends to your function. Lambda passes all of the records in the batch to the function in a single call, up to the payload limit for synchronous invocation (6 MB).\n  +   *Amazon Kinesis* \u2013 Default 100. Max 10,000.\n  +   *Amazon DynamoDB Streams* \u2013 Default 100. Max 10,000.\n  +   *Amazon Simple Queue Service* \u2013 Default 10. For standard queues the max is 10,000. For FIFO queues the max is 10.\n  +   *Amazon Managed Streaming for Apache Kafka* \u2013 Default 100. Max 10,000.\n  +   *Self-managed Apache Kafka* \u2013 Default 100. Max 10,000.\n  +   *Amazon MQ (ActiveMQ and RabbitMQ)* \u2013 Default 100. Max 10,000.\n  +   *DocumentDB* \u2013 Default 100. Max 10,000.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "MaximumRetryAttempts": {
      "description": "(Kinesis and DynamoDB Streams only) Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, Lambda retries failed records until the record expires in the event source.",
      "maximum": 10000,
      "type": "integer",
      "minimum": -1,
      "markdownDescription": "(Kinesis and DynamoDB Streams only) Discard records after the specified number of retries. The default value is -1, which sets the maximum number of retries to infinite. When MaximumRetryAttempts is infinite, Lambda retries failed records until the record expires in the event source.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "Topics": {
      "minItems": 1,
      "maxItems": 1,
      "uniqueItems": true,
      "description": "The name of the Kafka topic.",
      "type": "array",
      "items": {
        "minLength": 1,
        "type": "string",
        "maxLength": 249,
        "markdownDescription": "\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 249  \nPattern: ^[^.]([a-zA-Z0-9\\-_.]+)  \nUpdate requires: No interruption"
      },
      "markdownDescription": "The name of the Kafka topic.\n\n---\n\nRequired: No  \nType: Array  \nUpdate requires: No interruption"
    },
    "ScalingConfig": {
      "description": "(Amazon SQS only) The scaling configuration for the event source. For more information, see [Configuring maximum concurrency for Amazon SQS event sources](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency).",
      "$ref": "#/definitions/ScalingConfig",
      "markdownDescription": "(Amazon SQS only) The scaling configuration for the event source. For more information, see [Configuring maximum concurrency for Amazon SQS event sources](https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-max-concurrency).\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
    },
    "Enabled": {
      "description": "When true, the event source mapping is active. When false, Lambda pauses polling and invocation.\n Default: True",
      "type": "boolean",
      "markdownDescription": "When true, the event source mapping is active. When false, Lambda pauses polling and invocation.\n Default: True\n\n---\n\nRequired: No  \nType: Boolean  \nUpdate requires: No interruption"
    },
    "EventSourceArn": {
      "minLength": 12,
      "description": "The Amazon Resource Name (ARN) of the event source.\n  +   *Amazon Kinesis* \u2013 The ARN of the data stream or a stream consumer.\n  +   *Amazon DynamoDB Streams* \u2013 The ARN of the stream.\n  +   *Amazon Simple Queue Service* \u2013 The ARN of the queue.\n  +   *Amazon Managed Streaming for Apache Kafka* \u2013 The ARN of the cluster or the ARN of the VPC connection (for [cross-account event source mappings](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#msk-multi-vpc)).\n  +   *Amazon MQ* \u2013 The ARN of the broker.\n  +   *Amazon DocumentDB* \u2013 The ARN of the DocumentDB change stream.",
      "type": "string",
      "maxLength": 1024,
      "markdownDescription": "The Amazon Resource Name (ARN) of the event source.\n  +   *Amazon Kinesis* \u2013 The ARN of the data stream or a stream consumer.\n  +   *Amazon DynamoDB Streams* \u2013 The ARN of the stream.\n  +   *Amazon Simple Queue Service* \u2013 The ARN of the queue.\n  +   *Amazon Managed Streaming for Apache Kafka* \u2013 The ARN of the cluster or the ARN of the VPC connection (for [cross-account event source mappings](https://docs.aws.amazon.com/lambda/latest/dg/with-msk.html#msk-multi-vpc)).\n  +   *Amazon MQ* \u2013 The ARN of the broker.\n  +   *Amazon DocumentDB* \u2013 The ARN of the DocumentDB change stream.\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 12  \nMaximum Length: 1024  \nPattern: arn:(aws[a-zA-Z0-9-]*):([a-zA-Z0-9\\-])+:([a-z]{2}(-gov)?(-iso([a-z])?)?-[a-z]+-\\d{1})?:(\\d{12})?:(.*)  \nUpdate requires: Replacement"
    },
    "SelfManagedKafkaEventSourceConfig": {
      "description": "Specific configuration settings for a self-managed Apache Kafka event source.",
      "$ref": "#/definitions/SelfManagedKafkaEventSourceConfig",
      "markdownDescription": "Specific configuration settings for a self-managed Apache Kafka event source.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: Replacement"
    },
    "DocumentDBEventSourceConfig": {
      "description": "Specific configuration settings for a DocumentDB event source.",
      "$ref": "#/definitions/DocumentDBEventSourceConfig",
      "markdownDescription": "Specific configuration settings for a DocumentDB event source.\n\n---\n\nRequired: No  \nType:   \nUpdate requires: No interruption"
    },
    "TumblingWindowInSeconds": {
      "description": "(Kinesis and DynamoDB Streams only) The duration in seconds of a processing window for DynamoDB and Kinesis Streams event sources. A value of 0 seconds indicates no tumbling window.",
      "maximum": 900,
      "type": "integer",
      "minimum": 0,
      "markdownDescription": "(Kinesis and DynamoDB Streams only) The duration in seconds of a processing window for DynamoDB and Kinesis Streams event sources. A value of 0 seconds indicates no tumbling window.\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "BisectBatchOnFunctionError": {
      "description": "(Kinesis and DynamoDB Streams only) If the function returns an error, split the batch in two and retry. The default value is false.",
      "type": "boolean",
      "markdownDescription": "(Kinesis and DynamoDB Streams only) If the function returns an error, split the batch in two and retry. The default value is false.\n\n---\n\nRequired: No  \nType: Boolean  \nUpdate requires: No interruption"
    },
    "MaximumRecordAgeInSeconds": {
      "description": "(Kinesis and DynamoDB Streams only) Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, Lambda never discards old records.\n  The minimum valid value for maximum record age is 60s. Although values less than 60 and greater than -1 fall within the parameter's absolute range, they are not allowed",
      "maximum": 604800,
      "type": "integer",
      "minimum": -1,
      "markdownDescription": "(Kinesis and DynamoDB Streams only) Discard records older than the specified age. The default value is -1, which sets the maximum age to infinite. When the value is set to infinite, Lambda never discards old records.\n  The minimum valid value for maximum record age is 60s. Although values less than 60 and greater than -1 fall within the parameter's absolute range, they are not allowed\n\n---\n\nRequired: No  \nType: Integer  \nUpdate requires: No interruption"
    },
    "StartingPositionTimestamp": {
      "description": "With ``StartingPosition`` set to ``AT_TIMESTAMP``, the time from which to start reading, in Unix time seconds. ``StartingPositionTimestamp`` cannot be in the future.",
      "type": "number",
      "markdownDescription": "With ``StartingPosition`` set to ``AT_TIMESTAMP``, the time from which to start reading, in Unix time seconds. ``StartingPositionTimestamp`` cannot be in the future.\n\n---\n\nRequired: No  \nType: Number  \nUpdate requires: Replacement"
    },
    "Queues": {
      "minItems": 1,
      "maxItems": 1,
      "uniqueItems": true,
      "description": "(Amazon MQ) The name of the Amazon MQ broker destination queue to consume.",
      "type": "array",
      "items": {
        "minLength": 1,
        "type": "string",
        "maxLength": 1000,
        "markdownDescription": "\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 1  \nMaximum Length: 1000  \nPattern: [\\s\\S]*  \nUpdate requires: No interruption"
      },
      "markdownDescription": "(Amazon MQ) The name of the Amazon MQ broker destination queue to consume.\n\n---\n\nRequired: No  \nType: Array  \nUpdate requires: No interruption"
    },
    "FunctionResponseTypes": {
      "uniqueItems": true,
      "minLength": 0,
      "description": "(Streams and SQS) A list of current response type enums applied to the event source mapping.\n Valid Values: ``ReportBatchItemFailures``",
      "type": "array",
      "items": {
        "type": "string",
        "enum": [
          "ReportBatchItemFailures"
        ],
        "markdownDescription": "\n\n---\n\nRequired: No  \nType: String  \nAllowed Values: ReportBatchItemFailures  \nUpdate requires: No interruption"
      },
      "maxLength": 1,
      "markdownDescription": "(Streams and SQS) A list of current response type enums applied to the event source mapping.\n Valid Values: ``ReportBatchItemFailures``\n\n---\n\nRequired: No  \nType: Array  \nMaximum Length: 1  \nUpdate requires: No interruption"
    }
  },
  "attributes": {
    "Id": {
      "minLength": 36,
      "description": "",
      "type": "string",
      "maxLength": 36,
      "markdownDescription": "\n\n---\n\nRequired: No  \nType: String  \nMinimum Length: 36  \nMaximum Length: 36  \nPattern: [a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}  \nUpdate requires: No interruption"
    }
  }
}